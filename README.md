# DetectionYOLOv11 Модель обнаружения объектов на пользовательских данных с помощью YOLOv11
## Разметка данных ##
Для разметки было выбрано видео с максимальным количеством объектов. Всего было размечено 2975 кадров.
Для аннотации объектов было определено 3 класса:
    0: dishes
    1: cutllery
    2: other
Ссылка на размеченное видео из CVAT: <https://disk.yandex.ru/i/fM56DCYM_uz0-g>
Для обучения было выбрано 500 изображений, для валидации 100.
Для двух моделей обучения использовал разные наборы данных.
В связи с ограничением объема репозитория, сами изображения были расположены отдельно.
Ссылка на данные: <https://disk.yandex.ru/d/Q0ua99TXPU5obg>
Ссылка на разметку: <https://disk.yandex.ru/d/4PHbmuABBphbdQ>
Для работы с видео, обработкой кадров и распределением выборок использовался код написанный WorkToVideo.py
Пришлось создавать этот дополнительный код еще и потому, что мною часто используемый CVAT, все больше становиться платным и экспорт кадрированных изображений в беспланых услугах недоступен. Так как я уже разметил много данных, то пришлось отдельно кадрировать видео.

## Обучение модели ##
Обучение модели происходило с помощью предтренированной модели YOLOn11
Код и результат выполнения в DetectionYOLOv11.ipynb
Первая модель обучения проходил на 100 эпохах, автоматическим батчсайзом, сохранением контрольных точек и аугментацией данных (по 8-ми вариативным аргументам)
Прогресс обучения, представлен в виде текстовых отчетов каждой эпохи обучения на тренировочной и валидационной выборке.
Вторая модель обучения проходила на 200 эпохах, другом наборе данных и большей вариативностью аугментации данных, где основной упор был сделан на добавление аргументов отвечающих за повороты изображения.

### Результат обучение и прогресс обучения, можно увидеть с помощью TensorBoard
В виде графиков прогресса обучения на тренировочный и валидационных данных, на различных метриках: train/box_loss, train/cls_loss, train/dfl_loss, metrics/precision(B), metrics/recal(B), metrics/mAP50(B), metrics/mAP50-90(B)
### А также дополнительной информации в папке run0 для первой модели обучения и run для второйо модели обучения, где можно увидеть: 
1. **Достоверность F1 (F1 Confidence)**: показывает значение F1 (среднее гармоническое между точностью и полнотой) при различных порогах достоверности. Чем выше пик, тем лучше работает модель,
2. **Кривая точности и полноты (Precision-Recall Curve)**: иллюстрирует компромисс между точностью и полнотой при различных пороговых значениях. Чем ближе модель к правому верхнему углу, тем она лучше,
3. **Кривая точности и достоверности (Precision-Confidence Curve)**: показывает, как меняется точность при различных уровнях достоверности. В идеале точность должна быть высокой при всех уровнях достоверности,
4. **Кривая полноты-достоверности (Recall-Confidence Curve)**: показывает полноту при различных порогах достоверности. Вам нужна высокая полнота по всем параметрам,
5. **Матрица неточностей (Confusion Matrix)**: отражает эффективность классификации. Диагональные значения соответствуют правильным прогнозам, а недиагональные — ошибочным,
6. **Коррелограмма меток пользовательского набора данных**,
7. **Полный набор аргументов в файле args.yaml**, включая используемые по умолчанию, 
8. **Результат прогресса  обучения в формате csv** 
9. **Результирующие графики** train/box_loss, train/cls_loss, train/dfl_loss, metrics/precision(B), metrics/recal(B), metrics/mAP50(B), metrics/mAP50-90(B)
На втором отчете TensorBoard можно увидеть сравнительные характеристики двух моделей
## Предсказание модели ##
Проведем предсказание 10 тестовых изображений
Результаты предсказания модели 1 по ссылке: <https://disk.yandex.ru/d/AdTai_mtVeKpeQ>
Провел предсказание изображений по видео модели, результы после собрал в результирующее видео
Видео доступно по ссылке: <https://disk.yandex.ru/i/JKoW3MWDLAWBTQ>
# Итоги
В результате считаю, что тестовое задание я выполнил. Модель 1 показала лучший результат чем Модель 2, но это только на тестовых данных, которые формировались из этого же видео, в свою Модель 2 должна быть более устойчива к вариации
С практической точки зрения, конечно эти модель очень далеки от совершенства, так как данные для обучения маловариативные и в большей степени статичны, так что даже выборки из всех видео, каждого 10-го например кадра в этом случае ничего не дали, да и небыло временного ресурса размечать большое количество данных. На практике, необходима в первую очередь понимание задачи, например определение сколько приборов на столе или пустой ли стол и т.д. Тогда можно было бы с пониманием отнестить к созданию классов, сбору данных для достижения вариативности данных и балансировки классов.
